By showing strong normalisation, we seem to have good evidence that terms in the simply typed lambda-calculus are well behaved. Now we turn to proving that they "behave like functions", which will include a formal definition of what we mean by "behave like". However we do define the "behaviour" of a lambda-term, clearly it should be independent of the precise "implementation details" of how exactly the term is written.
In previous sections we gave some examples of terms that are equivalent in behaviour but are *not* alpha-beta-equivalent. For example:
![](Pasted%20image%2020231113111519.png)
Now we will specify exactly what we mean by "equivalent terms", and which behaviour we are concerned with. Intuitively, two programs should be considered equivalent if we could replace one with the other **in a larger program** without changing the result. In real programming terms, they would pass all the same tests, their documentation would be the same, and so on.
To formalise this we first need to decide what we consider a 'result'. Since function typed terms can be equivalent in behaviour while having non-trivial internal differences, we don't want to consider those to be results of computation. Therefore, we consider terms of type $\iota$ to be acceptable 'results': to see if they are equivalent it is sufficient to compared them in some environment using alpha-beta-equivalence. This idea is the motivation behind Definition 30, but before we can assert that we need to do some preparation.
We need to define the "larger programs" into which a term can be put. A **context** is like a lambda-term but with exactly one 'hole' in it. Substituting into this 'hole' is simpler than substituting for a variable because we do not allow abstraction over the 'hole'.
![](Pasted%20image%2020231113112413.png)
![](Pasted%20image%2020231113112455.png)
Note that substitution into a context is **not** capture avoiding. It behaves like a simple copy-and-paste of a term into a larger program. For this reason we need to restrict which terms we expect to behave like functions to only consider terms with no free variables. We call terms with no free variables **closed terms**. If we didn't restrict them like this, then the context could wrongly capture one of the free variables in $t$.
This restriction isn't very severe, because if we can find a good notion of equivalence for terms with no free variables, we can extend it to terms *with* free variables by declaring them to be equivalent if the corresponding closed terms where we abstracted over those free variables are equivalent.
In the lambda-calculus