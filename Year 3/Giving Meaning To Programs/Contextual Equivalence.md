By showing strong normalisation, we seem to have good evidence that terms in the simply typed lambda-calculus are well behaved. Now we turn to proving that they "behave like functions", which will include a formal definition of what we mean by "behave like". However we do define the "behaviour" of a lambda-term, clearly it should be independent of the precise "implementation details" of how exactly the term is written.
In previous sections we gave some examples of terms that are equivalent in behaviour but are *not* alpha-beta-equivalent. For example:
![](Pasted%20image%2020231113111519.png)
Now we will specify exactly what we mean by "equivalent terms", and which behaviour we are concerned with. Intuitively, two programs should be considered equivalent if we could replace one with the other **in a larger program** without changing the result. In real programming terms, they would pass all the same tests, their documentation would be the same, and so on.
To formalise this we first need to decide what we consider a 'result'. Since function typed terms can be equivalent in behaviour while having non-trivial internal differences, we don't want to consider those to be results of computation. Therefore, we consider terms of type $\iota$ to be acceptable 'results': to see if they are equivalent it is sufficient to compared them in some environment using alpha-beta-equivalence. This idea is the motivation behind Definition 30, but before we can assert that we need to do some preparation.
We need to define the "larger programs" into which a term can be put. A **context** is like a lambda-term but with exactly one 'hole' in it. Substituting into this 'hole' is simpler than substituting for a variable because we do not allow abstraction over the 'hole'.
![](Pasted%20image%2020231113112413.png)
![](Pasted%20image%2020231113112455.png)
Note that substitution into a context is **not** capture avoiding. It behaves like a simple copy-and-paste of a term into a larger program. For this reason we need to restrict which terms we expect to behave like functions to only consider terms with no free variables. We call terms with no free variables **closed terms**. If we didn't restrict them like this, then the context could wrongly capture one of the free variables in $t$.
This restriction isn't very severe, because if we can find a good notion of equivalence for terms with no free variables, we can extend it to terms *with* free variables by declaring them to be equivalent if the corresponding closed terms where we abstracted over those free variables are equivalent.
By deciding to only concern ourselves with closed terms, we can simplify the notion of contexts. This is because for closed terms, there is little difference between substitution into a context and applying a term to an argument. This is true because for these terms there is also little difference between ordinary and capture-avoiding substitution.
![](Pasted%20image%2020231113114927.png)
(I think theres a typo here and that $C_y$ should be $T^C_y$.)
Simple: If you have a context $C$ that doesn't contain $y$, and a term $T^C_y$ that is the same as $C$ but with $y$ in the place of $\square$, performing a substitution into $C$ is alpha-equivalent to performing a capture-avoiding substitution into $T^C_y$. 

This is one way in which the more advanced features of the simply typed lambda calculus actually make it easier to study. If we were studying a language with no notion of 'functions' which allow us to represent a context as a term, we would have to treat contexts as a completely separate notion. This corresponds to the fact that in a language with 'functions' we can wrap up tests as a piece of code, whereas if the language lacks these features, tests which embed the code to be tested in a larger program would have to be constructed by external scripts, which would be more unwieldy.
Recalling that the results of computation are terms of type $\iota$, we need to define the notion of a context which we can use to get a 'test result' from a term of a given type $\tau$. We want these terms to have a 'hole' in the such that if we replace the 'hole' with a term of type $\sigma$, the resulting term has type $\iota$. It is also useful to consider the general idea of a context which transforms a term of type $\sigma$ into one of some type $\tau$. As usual, we have to allow for free variables to appear in our terms and so we have to include a type environment.
![](Pasted%20image%2020231113134158.png)
Simple: $C$ is a $(\Gamma,\sigma,\tau)$-context if, for every term $t$ with type $\sigma$, substituting $t$ into $C$ produces a term that is typed $\tau$.
Note that because we have no built-in data types, $\Gamma$ cannot be empty. The only way to get a term of type $\iota$ is to assume we have a variable of that type in $\Gamma$. For an example of why this is, see:
![](Pasted%20image%2020231113135202.png)
![](Pasted%20image%2020231113135329.png)