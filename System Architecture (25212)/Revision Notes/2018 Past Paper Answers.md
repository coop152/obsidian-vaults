1a. Compulsory miss: Occurs when the cache has just been started, for example when the program first starts. The cache doesn't contain anything yet, so any reads or writes will necessarily cause a cache miss. This kind of miss happens on any kind of cache.
Capacity miss: Occurs when the cache is too full to hold a new cache line, and must evict an old cache line to make space. This kind of miss is most common on a fully associative cache. 
Conflict miss: Occurs when the cache already holds an old cache line with the same location (or index) as the cache line that is being inserted, meaning that the old cache line must be evicted. This kind of miss is most likely to happen in a direct mapped cache, is less likely to happen in a set-associative cache, and cannot happen in a fully associative cache.

1b. Temporal locality: When something in memory is used, it will likely be used again soon. To exploit this, you may implement "blocking"; that is, breaking a problem down into smaller chunks so that the working set of data can fit entirely in the cache. This improves performance in algorithms where data is repeatedly used, by preventing data that is still in use from being evicted from the cache.
Spacial locality: When something in memory is used, it is likely that something nearby will also be used. To exploit this you may use "flat" data structures over ones with more indirection; using an array allows a cache with wide cache lines to retrieve multiple entries in the array at once, while a linked list or similar structure will only retrieve one element at a time, drastically increasing the number of cache misses.

3a. Dependencies: ()