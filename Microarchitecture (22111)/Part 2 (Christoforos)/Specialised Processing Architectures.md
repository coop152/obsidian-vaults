**GPU**s can perform a limited set of specific instructions, but on large amounts of data in parallel. This is suited for graphics rendering, where lots of unrelated, identical mathematical operations are being done en masse. This parallelism gives GPUs high throughput.

**CPU**s can perform a large set of varied instructions, but only on limited amounts of data at a time and in a serial manner. This is suited for general computing, where programs can be varied and each operation may or may not rely heavily on others. Due to this, CPUs have low latency to perform these serial operations quickly but lower throughput due to the low amount of parallelism.